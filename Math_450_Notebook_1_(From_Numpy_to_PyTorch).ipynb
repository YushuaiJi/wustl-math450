{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Math 450 Notebook 1 (From Numpy to PyTorch).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNEPZENlRP49Z5YkzHBSwu3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scaomath/wustl-math450/blob/main/Math_450_Notebook_1_(From_Numpy_to_PyTorch).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOISA5pYlwLc"
      },
      "source": [
        "# Coding Lecture 1 of Math 450\n",
        "\n",
        "\n",
        "## Welcome to Google Colab\n",
        "We are using Google Colab~\n",
        "\n",
        "This is a text cell. It uses Markdown synt\n",
        "ax.\n",
        "\n",
        "For example, we can enter math inline by `$ $`: $E = mc^2$, and `$$   $$` for a line of equation:\n",
        "$$\n",
        "\\int^1_0 f(x) dx + \\int^1_0 f^{-1}(x) dx  = 1. \n",
        "$$\n",
        "\n",
        "Python code:\n",
        "```python\n",
        "import numpy as np\n",
        "x = np.array([9,1,1])\n",
        "print(x)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOmOayLG9QH1",
        "outputId": "3311bd91-3c01-4cae-defc-cdabdaa27207"
      },
      "source": [
        "from time import time\n",
        "print(\"Welcome to Math 450.\")\n",
        "print(f\"{time():.2f}\") # f-string"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Welcome to Math 450.\n",
            "1611957316.34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi3dvERjmAJk"
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZFQ21iGoUBS"
      },
      "source": [
        "## Introduction of PyTorch and GPUs\n",
        "\n",
        "Colab uses an NVIDIA Tesla T4, and Kaggle uses Nvidia Tesla P100, both of which are extremely powerful GPUs only subpar vs the new Ampere GPUs (RTX 3090, A4000, A8000). \n",
        "\n",
        "A GPU instance has a time limit (12h on Colab, 9h on Kaggle). However, Colab's GPU limit is more shady as stated in the \n",
        "> Colab resources are not guaranteed and not unlimited, and the usage limits sometimes fluctuate. This is necessary for Colab to be able to provide resources for free. For more details, see Resource Limits.\n",
        "\n",
        "If you want to get into serious Machine Learning, my personal recommendation is to build a computer around an RTX 3060 12GB under a budget and learn Linux. If you started working on CV (computer vision) or NLP (natural language processing), then it is recommended to get an RTX 3090."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "y1f0hkQEnv-Y",
        "outputId": "8e000b65-242f-4ac4-d2b9-f27ac59367c9"
      },
      "source": [
        "torch.__version__ # cu means cuda"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.7.0+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBzcuYAz_I_A",
        "outputId": "ad766df1-b98e-4604-ad11-0bed42ff36ec"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HPSJ9yb_nBb",
        "outputId": "3c34939c-a90f-40fa-bdbf-a9639f256787"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jan 29 21:14:08 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8     9W /  70W |     10MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJTCNLGDpQD1"
      },
      "source": [
        "### Compare a `torch.tensor` with a `numpy.ndarray`\n",
        "\n",
        "- Initialization\n",
        "- Convert one to the other and vice versa\n",
        "- Common methods (functions) associated with them\n",
        "- PyTorch has a special \"in-place\" operation which has an underscore `_` as a suffix of a certain function, meaning they will modify the underlying variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4zzNEJt7_3kF",
        "outputId": "a359d416-e72d-4f53-c0c4-5ec3f1c930e9"
      },
      "source": [
        "np.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.19.5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJxQCtW7n9zi"
      },
      "source": [
        "x = np.array(range(10))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AD5Tdn1AKBe",
        "outputId": "7906e032-4cff-40ad-b41a-fc867bee23a5"
      },
      "source": [
        "np.sum(x)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hklUEsNARFK",
        "outputId": "1aca1077-8fc7-4137-8943-f2be7e1e6dcd"
      },
      "source": [
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 5 6 7 8 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWOhaiQlAWXh",
        "outputId": "6d030ca6-de7a-4a37-f744-5a213ea93295"
      },
      "source": [
        "x.sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKeTXRpxAngL",
        "outputId": "cf8c5800-f333-4d61-ffca-154414d2e3be"
      },
      "source": [
        "torch.tensor(list([1,2,5]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ho9fpB0opiGB",
        "outputId": "018a4be0-b980-42dd-c364-f588941f9354"
      },
      "source": [
        "x_t = torch.tensor(range(10))\n",
        "print(x_t)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xldxF5BA41o",
        "outputId": "41416df5-7b69-441b-dbc2-8e43205d55b2"
      },
      "source": [
        "x_t.sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(45)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhk55DgtBDrO",
        "outputId": "8887291f-18e3-4376-99b6-cfd274d77935"
      },
      "source": [
        "torch.tensor(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW6_0NGdBLDs",
        "outputId": "db4517dc-e0a0-432c-c41b-fe83c19c8202"
      },
      "source": [
        "x_np = x_t.numpy()\n",
        "print(type(x_np))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlDt66IDBX6F",
        "outputId": "90f3b293-05be-4a6e-bbc0-890dc92cdfbb"
      },
      "source": [
        "# relu\n",
        "x.clip(min=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 5, 5, 5, 5, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4g4P8fpBnvB",
        "outputId": "b9f2aabb-f781-4dce-c28f-979a0c6a133a"
      },
      "source": [
        "np.array([-0.3, -0.1, 2, 4]).clip(min=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 2., 4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4nE4cIEBw1E",
        "outputId": "496e0eee-56cf-4737-e623-a3f7bba97279"
      },
      "source": [
        "x_t.clamp(min=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7Hd93_3B78X",
        "outputId": "52eafc71-724e-4866-ad52-17c4a57e8bb5"
      },
      "source": [
        "x_t.add(-5).clamp(min=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 1, 2, 3, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mb9xkx8KCN_h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efbde6f8-a215-4d4c-93cf-f0df4f0d464b"
      },
      "source": [
        "print(x_t.add(1))\n",
        "print(x_t)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaTnURZ7CzA4",
        "outputId": "fa23b7fc-954d-40cd-aa60-79ed1d87a804"
      },
      "source": [
        "x_t.add_(1) # in-place operations"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9F-VL0g4C4kl",
        "outputId": "dd8b1c2a-1faf-4389-a3d8-508ff294d640"
      },
      "source": [
        "print(x_t)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8RXvE-1rJqu"
      },
      "source": [
        "## Neural network\n",
        "\n",
        "We want to implement the following key component of a multi-layer perceptron neural net: \n",
        "\n",
        "### A single perceptron in the $l$-th layer.  \n",
        "\n",
        "<img src=\"https://sites.wustl.edu/scao/files/2021/01/neuron-1.png\" alt=\"drawing\" width=\"800\"/>\n",
        "\n",
        "- Input: $\\mathbf{a} \\in \\mathbb{R}^d$ ($d$ is the dimension of an input vector).\n",
        "- Output: $\\hat{a}$ (if this perceptron is the final one, then the output will try to approximating the actual target value $y$).\n",
        "- The formula (with bias) is then\n",
        "$$\n",
        "\\hat{a} = f(\\mathbf{w} \\cdot \\mathbf{a} + b) = f (w_1 a_1 + w_2 a_2 + ... + w_d a_d + b)\n",
        "$$\n",
        "Here, $\\mathbf{w} \\in \\mathbb{R}^d$ is a weight vector; $b \\in \\mathbb{R}$ is a bias; and $f(\\cdot)$ denotes the nonlinear activation function we learned in Lecture 2:\n",
        "$$\n",
        "f (x) = \\begin{cases}\n",
        "x & \\text{if } x>0,\n",
        "\\\\\n",
        "0 & \\text{if } x\\leq 0.\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "\n",
        "### Multi-layer, multiple perceptrons per layer\n",
        "If we have $m$ perceptrons in a single layer, for example layer 2:\n",
        "<img src=\"https://sites.wustl.edu/scao/files/2021/01/neural_net_3l.png\" alt=\"drawing\" width=\"800\"/>\n",
        "\n",
        "Our neural network has parameters $(W, b) := \\big(W^{(1)},b^{(1)},W^{(2)},b^{(2)}\\big)$.\n",
        "\n",
        "* $W^{(l)} = \\big(w^{(l)}_{ij}\\big)$ to denote the weight matrix, where the entry-$ij$ is associated with the connection between unit $j$ in layer $l$, and unit $i$ in layer $l+1$. Note the order of the indices, $j$ is the closer to the input that this matrix is acting on \n",
        "\n",
        "* $b^{(l)}_i$ is the bias associated with unit $i$ in layer $l+1$. \n",
        "\n",
        "In our example above, we have $W^{(1)}\\in \\mathbb{R}^{3×2}$, and $W^{(2)}\\in \\mathbb{R}^{1×3}$. Note that bias units do not have inputs or connections going into them, we write their output the value $+1$ for convenience. When we count the number of units in layer $l$, we do not count the bias unit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbdnqiqhyixR"
      },
      "source": [
        "## Representation of the neural network\n",
        "\n",
        "### Step 1: component-wise representation\n",
        "We write $a^{(l)}_i$ to denote the activation or output value of unit $i$ in layer $l$. For $l=1$, $a^{(1)}_i= x_i$ denotes the $i$-th input to this network. Given a fixed set of parameters $(W,b)$, and the input $\\mathbf{x}$, the neural network above defines a model function $h(\\mathbf{x}; W, b)$ made of layers of function compositions that outputs a real number. Specifically, the computation that this neural network represents is given by:\n",
        "$$\n",
        "a_1^{(2)} = f\\big(w_{11}^{(1)}x_1 + w_{12}^{(1)} x_2  + b_1^{(1)}\\big)\n",
        "$$\n",
        "$$\n",
        "a_2^{(2)} = f\\big(w_{21}^{(1)}x_1 + w_{22}^{(1)} x_2 + b_2^{(1)}\\big) \n",
        "$$\n",
        "$$\n",
        "a_3^{(2)} = f\\big(w_{31}^{(1)}x_1 + w_{32}^{(1)} x_2 + b_3^{(1)}\\big) \n",
        "$$\n",
        "and the output \n",
        "$$\n",
        "h(\\mathbf{x}; W,b) =\\hat{y} =  a_1^{(3)} =  f\\big(w_{11}^{(2)} a_1^{(2)} + w_{12}^{(2)} a_2^{(2)} + w_{13}^{(2)} a_3^{(2)} + b_1^{(2)}\\big) \n",
        "$$\n",
        "\n",
        "### Step 2: from component to vector to matrix\n",
        "\\begin{align*}\n",
        "a_1^{(l+1)} = f\\big(\\mathbf{w}_1^{(1)} \\cdot \\mathbf{a}^{(l)} + b_1^{(l)}\\big) \n",
        "\\\\\n",
        "a_2^{(l+1)} = f\\big(\\mathbf{w}_2^{(1)} \\cdot \\mathbf{a}^{(l)} + b_2^{(l)}\\big) \n",
        "\\\\\n",
        "a_3^{(l+1)} = f\\big(\\mathbf{w}_3^{(1)} \\cdot \\mathbf{a}^{(l)} + b_3^{(l)}\\big) \n",
        "\\end{align*}\n",
        "The weight matrix $W^{(1)}$ is then consisting of $\\mathbf{w}_j^{(1)}$ as its $j$-th row.\n",
        "\n",
        "\n",
        "### Step 3: Matrix-vector representation\n",
        "If we allow the activation function $f(\\cdot)$ to act on vectors in an element-wise fashion: $f([\\mathbf{z}_1,\\mathbf{z}_2,\\mathbf{z}_3])=[f(\\mathbf{z}_1),f(\\mathbf{z}_3),f(\\mathbf{z}_3)]$, then we can write the equations above more compactly as:\n",
        "$$\\begin{aligned}\n",
        "\\mathbf{z}^{(2)} &= W^{(1)} \\mathbf{x} + \\mathbf{b}^{(1)} \\\\\n",
        "\\mathbf{a}^{(2)} &= f(\\mathbf{z}^{(2)}) \\\\\n",
        "\\mathbf{z}^{(3)} &= W^{(2)} \\mathbf{a}^{(2)} + \\mathbf{b}^{(2)} \\\\\n",
        "h(\\mathbf{x}; W, b) &= \\mathbf{a}^{(3)} = f(\\mathbf{z}^{(3)})\n",
        "\\end{aligned}\n",
        "$$\n",
        "More generally, recalling that $\\mathbf{a}^{(0)}=\\mathbf{x}$ also denotes the values from the input layer, then given layer $l$'s activations $\\mathbf{a}^{(l)}$, we can compute layer $(l+1)$'s activations $\\mathbf{a}^{(l+1)}$ as:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\mathbf{z}^{(l+1)} &= W^{(l)} \\mathbf{a}^{(l)} + \\mathbf{b}^{(l)}   \\\\\n",
        "\\mathbf{a}^{(l+1)} &= f(\\mathbf{z}^{(l+1)})\n",
        "\\end{aligned}\n",
        "$$\n",
        "By organizing the parameters in matrices and using matrix-vector operations, we can take advantage of fast linear algebra routines to quickly perform calculations in our network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CodTGYNBxgPD"
      },
      "source": [
        "\n",
        "## Linear algebra: Numpy vs PyTorch\n",
        "### Operations needed to implement this model\n",
        "- Inner product\n",
        "- Matrix-vector multiplication\n",
        "- Element-wise operation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj9LxVPZrJYj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b27ddf1-3e08-4242-932e-f06d9a1689f5"
      },
      "source": [
        "# recall numpy's various operations\n",
        "a = np.array([[1,0], [2,3]])\n",
        "print(a)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 0]\n",
            " [2 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Etu5SaUoFV6z",
        "outputId": "91fab364-3e87-4d90-9dc5-e97b517770ce"
      },
      "source": [
        "x = np.array([2,-1])\n",
        "print(x)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2 -1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBbRkjglFgep",
        "outputId": "1e3a9376-0a23-489c-eb94-3708e889eff1"
      },
      "source": [
        "# a*x is not the correct way to implement matrix-vector multiplication\n",
        "a.dot(x) # a times x"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1ncWu-Y1hoZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b043570d-55cd-4d98-f0ac-4dbe1b4307d5"
      },
      "source": [
        "# pytorch's counterparts\n",
        "a_t = torch.tensor(a)\n",
        "x_t = torch.tensor(x)\n",
        "print(a_t,'\\n', x_t)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 0],\n",
            "        [2, 3]]) \n",
            " tensor([ 2, -1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "sc6pRlChGEPw",
        "outputId": "6025b8f2-e7c7-4a57-d9a6-4b95227679f5"
      },
      "source": [
        "a_t.mm(x_t)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-de99422aa3a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: mat2 must be a matrix"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7cv3A-3GguA",
        "outputId": "06e84677-f827-4687-be70-44ba069be440"
      },
      "source": [
        "x_t.reshape(-1,1).size() # -1 means that we do not specify that dimension"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPfwJTldGW3P",
        "outputId": "7eeed050-29d5-4297-a7ea-cca5289b9c72"
      },
      "source": [
        "# x_t has to be a tensor of Size(2,1)\n",
        "a_t.mm(x_t.reshape(-1,1))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2],\n",
              "        [1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Llbhv8FGGyjG",
        "outputId": "807655ab-fd2f-43fc-9c67-4f97acd5d06e"
      },
      "source": [
        "# relu\n",
        "y_t = torch.randn((2,5))\n",
        "print(y_t)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.5825, -0.0327,  0.1823, -0.8353,  1.0416],\n",
            "        [-0.6860,  1.2339, -0.1908, -0.0246, -0.5685]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFPLplUkHDEE",
        "outputId": "fba793f8-2c5b-41aa-98c3-5ae40b9a23f3"
      },
      "source": [
        "y_t.clamp(min=0)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5825, 0.0000, 0.1823, 0.0000, 1.0416],\n",
              "        [0.0000, 1.2339, 0.0000, 0.0000, 0.0000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIEBSLQgHIUu",
        "outputId": "448ce5d1-3245-4901-e15e-f1138cf533dd"
      },
      "source": [
        "y = y_t.numpy()\n",
        "print(y)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.5824803  -0.03270331  0.18226774 -0.8352577   1.0416421 ]\n",
            " [-0.68601185  1.2339315  -0.19084905 -0.02458323 -0.56846607]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdXnWMlMHOJO",
        "outputId": "57b94a94-82df-4f9a-a9dd-451e0be83e85"
      },
      "source": [
        "# boolean array\n",
        "y>0"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True, False,  True, False,  True],\n",
              "       [False,  True, False, False, False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuCvSHapHaRO",
        "outputId": "b144e886-3c6c-45d0-ceac-9a1399625341"
      },
      "source": [
        "# boolean array as indices\n",
        "y[y<=0] = 0 # first y<=0 is getting indices of y such that its entry is <= 0\n",
        "# then we set these entries to be 0\n",
        "print(y)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.5824803  0.         0.18226774 0.         1.0416421 ]\n",
            " [0.         1.2339315  0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ky8P54EkJUu6",
        "outputId": "99856524-cea8-4131-d458-16d6aed15c25"
      },
      "source": [
        "y_t[y_t <= 0] = 0 # same syntax applies to torch tensor\n",
        "print(y_t)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.5825, 0.0000, 0.1823, 0.0000, 1.0416],\n",
            "        [0.0000, 1.2339, 0.0000, 0.0000, 0.0000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qWsJVkq2Cr3"
      },
      "source": [
        "## Final remark\n",
        "In the actual implementation, the data normaly comes in batch, i.e., a matrix. For example, input is a matrix $X \\in \\mathbb{R}^{N \\times d}$, $N$ is a number of samples in a batch, each row represents a sample $\\mathbf{x} \\in \\mathbb{R}^{1\\times d}$. The weight matrix $W$ is actually formulated as:\n",
        "$$\n",
        "W = \\left(\n",
        "\\begin{array}{cccc}| & | & | & | \\\\\n",
        "\\mathbf{w}_1 & \\mathbf{w}_2 & \\cdots & \\mathbf{w}_m \\\\\n",
        "| & | & | & |\n",
        "\\end{array}\\right),\n",
        "$$\n",
        "if the output dimension of the layer of interest is $m$. The vectorized formulation is, for example, from the input (layer 0, dimension $d$) to layer 1 (dimension $m$)\n",
        "$$\n",
        "A^{(1)} = X W^{(0)} + B\n",
        "$$\n",
        "where $X \\in \\mathbb{R}^{N \\times d}$, $W^{(0)} \\in \\mathbb{R}^{d\\times m}$ (input from $d$ perceptrons, output from $m$ perceptrons), $B$ is a matrix with each row being the same $\\mathbf{b} \\in \\mathbb{R}^{1\\times m}$ (layer 1 has $m$ perceptrons and has $m$ biases if applicable)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "256jKD664nvU"
      },
      "source": [
        "\n",
        "# demo a matrix plus a vector (dimension match)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVNHOhtT4vr_"
      },
      "source": [
        "# demo using torch.randn()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}